## Data Center Networks (DCN): Structure and Components

A Data Center (DC) is not a single, monolithic super-computer. Instead, its massive processing power and storage capacity are achieved by aggregating a vast number of **Commercial Off-The-Shelf (COTS)** components.

The **Data Center Network (DCN)** is the critical infrastructure that interconnects all these components, allowing them to work together as a cohesive whole. The design of this network is essential for applications to run efficiently and predictably.

### Key Physical Components

The fundamental building blocks of a modern data center are standardized and modular, designed to be stacked and scaled massively.

#### Servers and Racks
* **Servers:** These are the computers that provide processing and storage services. 
    * In data centers, they are often **blade servers**, stripped-down computers with a modular design optimized for density.
* **Racks:** Servers are mounted in standardized frames called racks. A single 42U rack, for example, can hold up to 42 1U-sized servers. Multiple blade servers can be housed in a single **blade enclosure**, which provides shared power, cooling, and network interfaces for the servers it holds.

#### Ethernet Switches
Used to interconnect the thousands of servers within a data center.
* **Top-of-Rack (ToR) Switch:** A common design practice is to place a switch at the top of each rack. This ToR switch connects all the servers within that rack.
* **Commodity Hardware:** These are typically COTS Ethernet switches, with a standard number of ports such as 24, 48, or 64.
* **Higher-Level Switches:** ToR switches are then connected to higher-level switches (sometimes called **Aggregation** or **End-of-Row (EoR)** switches) that link multiple racks together.

### The Data Center Environment & Connectivity

Beyond the computing hardware, a data center is a highly controlled physical facility that includes:
* **Power:** Redundant power supplies, including Uninterruptible Power Supplies (**UPS**) and **backup generators**, are critical for continuous operation.
* **Cooling:** Massive air conditioning systems are required to dissipate the heat generated by the servers and keep them within their recommended temperature range.
* **Security and Safety:** This includes physical security systems, fire protection, and environmental monitoring.
* **External Connectivity:** Data centers connect to the external internet via high-capacity **border routers** and use **load balancers** to distribute incoming traffic among the servers.

### Data Center Traffic Patterns

A key characteristic of data center traffic is that the vast majority of it is internal.
* **East-West Traffic:** This is communication between servers *within* the data center. It accounts for the bulk of the traffic, with some studies indicating it makes up around 80% of all packets. This traffic is generated by applications that require coordination between many servers, such as distributed databases or big data analytics jobs.
* **North-South Traffic:** This is traffic that enters or leaves the data center from or to the external internet (e.g., a user requesting a web page).

Understanding that most traffic is internal is fundamental to designing an efficient DCN topology.

Because the internal, East-West traffic pattern is dominant, the primary goal of modern DCN topology design has shifted. Instead of just efficiently getting traffic in and out of the data center, the goal is to provide high, uniform, and predictable bandwidth between any two servers in the facility.

This is why newer topologies like ***Fat-Tree*** and ***Clos Networks*** have become standard. 
* They are specifically designed to solve the East-West bottleneck by providing many parallel paths and much higher bisection bandwidth, ensuring that internal communication does not get choked at the core of the network.