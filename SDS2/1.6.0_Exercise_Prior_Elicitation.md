```markdown
# Source Document: Bayesian Analysis of Binomial Data with Prior Elicitation
## Overview
This document summarizes an R exercise demonstrating a Bayesian analysis for estimating an unknown probability ($\theta$) using a Binomial likelihood model. The key focus is on **prior elicitation**: determining the parameters of a conjugate Beta prior distribution, $\pi(\theta) \sim Beta(a,b)$, such that it reflects specific prior beliefs before incorporating observed data. The analysis then proceeds using this elicited prior to find the posterior distribution and derive inferences.
The scenario involves estimating the prevalence ($\theta$) of a disease based on $N=20$ tests where $y=0$ infections were observed.
## R Code with Corrections and Explanations
```R
# SMDS-2 2024-2025 # Lecture week #02 -----------------------------------------
# Based on Example 1.2.1 p.3 PH Book (Binomial Model)
# Adapted to focus on prior elicitation first.
# Clear the R environment workspace
rm(list=ls())
# --- 1) PRIOR ELICITATION FOR A CONJUGATE BINOMIAL MODEL ---
# Goal: Find Beta(a, b) hyperparameters matching these prior beliefs:
# Belief 1: Prior mean E[θ] = 0.1.
# Belief 2: Prior P(0.05 <= θ <= 0.20) ≈ 0.70.
# *Discussion Point*: This prior mean (0.1) comes from belief/knowledge *before*
# seeing the N=20, y=0 data (e.g., expert opinion, previous studies),
# it is NOT derived from the current dataset. Prior elicitation translates
# such beliefs into a mathematical distribution.
# --- Using Reparameterization for Elicitation ---
# Use Beta distribution parameterized by mean (μ) and concentration (ψ):
# μ = a / (a+b); ψ = a + b => a = μ * ψ; b = (1-μ) * ψ
# *Discussion Point*: (μ, ψ) are also hyperparameters, just like (a,b). This
# parameterization is often more intuitive for elicitation.
# Set the target prior mean based on Belief 1
mu_0 <- 0.1
# Define function to calculate P(0.05 <= θ <= 0.20) for a Beta(μ=0.1, ψ)
prior_prob <- function(psi){
# Ensure psi is positive for valid Beta parameters
if (psi <= 0) return(NA)
a <- mu_0 * psi
b <- (1 - mu_0) * psi
# Beta parameters a,b must be > 0
if (a <= 0 || b <= 0) return(NA)
pbeta(0.20, shape1=a, shape2=b) - pbeta(0.05, shape1=a, shape2=b)
}
# Define a target function whose root is the psi making prior_prob(psi) == 0.7
lookforpsi <- function(psi, target_prob = 0.7){
prob_content <- prior_prob(psi)
if (is.na(prob_content)) return(NA) # Handle invalid psi
prob_content - target_prob
}
# Find the root numerically in a reasonable interval for psi (concentration)
# Increase upper bound if needed, ensure interval brackets the root (f(lower)*f(upper) < 0)
lower_bound_psi <- 2 # Start above 0, need a*psi and (1-a)*psi > 0
upper_bound_psi <- 100 # Adjust if root not found
# Check if function changes sign in interval (needed for uniroot)
if (is.na(lookforpsi(lower_bound_psi)) || is.na(lookforpsi(upper_bound_psi)) || lookforpsi(lower_bound_psi) * lookforpsi(upper_bound_psi) >= 0) {
print("Error: Function does not span zero in the chosen interval. Adjust interval or check target_prob.")
# Handle error appropriately, maybe stop or use default psi
# For this example, we know a solution exists, adjust interval if needed.
# Example: trying a wider interval if the first fails
upper_bound_psi <- 200
if (is.na(lookforpsi(lower_bound_psi)) || is.na(lookforpsi(upper_bound_psi)) || lookforpsi(lower_bound_psi) * lookforpsi(upper_bound_psi) >= 0) {
stop("Cannot find suitable interval for uniroot.")
}
}
oo <- uniroot(f=lookforpsi, interval=c(lower_bound_psi, upper_bound_psi))
my_psi <- oo$root # This is the elicited concentration parameter ψ
# Calculate the final elicited prior hyperparameters a and b
my_prior_a <- mu_0 * my_psi
my_prior_b <- (1 - mu_0) * my_psi
# Display the elicited parameters
print(paste("Elicited Prior: Beta(a =", round(my_prior_a, 3), ", b =", round(my_prior_b, 3), ")"))
print(paste("Corresponding psi =", round(my_psi, 3)))
# Verify the probability content using the found psi value
print(paste("Check: Prior P(0.05 <= theta <= 0.20) =", round(prior_prob(my_psi), 3)))
# --- 2) POSTERIOR ANALYSIS (Using the Elicited Prior) ---
# Observed data:
y_obs <- 0 # Number of successes
N <- 20 # Number of trials
# Calculate posterior hyperparameters using conjugate update rule:
my_posterior_a <- my_prior_a + y_obs
my_posterior_b <- my_prior_b + (N - y_obs)
print(paste("Posterior: Beta(a =", round(my_posterior_a, 3), ", b =", round(my_posterior_b, 3), ")"))
# --- Visualization ---
par(mfrow=c(1,1))
# Plot Prior
curve(dbeta(x, shape1=my_prior_a, shape2=my_prior_b), from=0, to=1, col="blue", lwd=2, ylim=c(0,25), xlab=expression(theta), ylab="Density", n=1000)
# Plot Posterior
curve(dbeta(x, shape1=my_posterior_a, shape2=my_posterior_b), from=0, to=1, add=TRUE, col="orange", lwd=2, n=1000)
# Scaled Likelihood
likelihood <- function(theta){ dbinom(y_obs, size=N, prob=theta) } # Use dbinom for exact likelihood value
# Find appropriate scaling factor (e.g., based on max density)
scale_factor <- max(dbeta(seq(0,1,length.out=200), my_posterior_a, my_posterior_b)) / max(likelihood(seq(0,1,length.out=200))) * 0.6
curve(scale_factor * likelihood(x), add=TRUE, col="red", lwd=2, lty=5, n=1000)
# Add legend, means, MLE
legend("topright", legend=c("Elicited Prior", "Posterior", "Scaled Likelihood"), col=c("blue", "orange", "red"), lty=c(1,1,5), lwd=2)
points(my_prior_a/(my_prior_a+my_prior_b), 0, pch=16, cex=1.5, col="blue") # Prior mean
posterior_mean <- my_posterior_a/(my_posterior_a+my_posterior_b)
points(posterior_mean, 0, pch=16, cex=1.5, col="orange") # Posterior mean
mle <- y_obs/N
points(mle, 0, pch=16, cex=1.5, col="red") # MLE
title(main="Bayesian Update with Elicited Prior")
# --- Posterior Summaries & Inference ---
# Point Estimates
print(paste("Posterior Mean:", round(posterior_mean, 4)))
posterior_median <- qbeta(0.5, shape1=my_posterior_a, shape2=my_posterior_b)
print(paste("Posterior Median:", round(posterior_median, 4)))
if (my_posterior_a > 1 && my_posterior_b > 1) {
posterior_mode <- (my_posterior_a - 1) / (my_posterior_a + my_posterior_b - 2)
} else if (my_posterior_a <= 1 && my_posterior_b > 1) { posterior_mode <- 0
} else if (my_posterior_a > 1 && my_posterior_b <= 1) { posterior_mode <- 1
} else { posterior_mode <- "0 or 1" }
print(paste("Posterior Mode:", round(posterior_mode, 4))) # Handle non-numeric case if needed
# Interval Estimates (95% Credible Intervals)
alpha <- 0.05
# Equal-Tailed
posterior_qf <- function(p){ qbeta(p, shape1=my_posterior_a, shape2=my_posterior_b) }
lower_ET <- posterior_qf(alpha/2)
upper_ET <- posterior_qf(1 - alpha/2)
print(paste("95% ET Credible Interval: [", round(lower_ET, 4), ",", round(upper_ET, 4), "]"))
# HPD
# library(TeachingDemos) # Make sure package is loaded
interval_estimate_hpd <- TeachingDemos::hpd(posterior.icdf = posterior_qf, conf = 1 - alpha)
print(paste("95% HPD Credible Interval: [", round(interval_estimate_hpd[1], 4), ",", round(interval_estimate_hpd[2], 4), "]"))
# Hypothesis Testing (e.g., H0: theta <= 0.1 vs H1: theta > 0.1)
posterior_prob_H0 <- pbeta(0.1, shape1=my_posterior_a, shape2=my_posterior_b)
print(paste("Posterior P(theta <= 0.1):", round(posterior_prob_H0, 3)))
# Bayes Factor (comparing H0: theta <= 0.1 vs H1: theta > 0.1)
prior_prob_H0 <- pbeta(0.1, shape1=my_prior_a, shape2=my_prior_b)
prior_odds_01 <- prior_prob_H0 / (1 - prior_prob_H0)
posterior_odds_01 <- posterior_prob_H0 / (1 - posterior_prob_H0)
BF_01 <- posterior_odds_01 / prior_odds_01
print(paste("Bayes Factor BF(H0:<=0.1 vs H1:>0.1):", round(BF_01, 3)))
# Bayes Factor (comparing H0: theta >= 0.1 vs H1: theta < 0.1)
# *Discussion Point*: This calculates BF for the swapped hypotheses.
BF_10 <- 1 / BF_01 # Evidence for H1 (theta < 0.1) relative to H0 (theta >= 0.1)
print(paste("Bayes Factor BF(H1:<0.1 vs H0:>=0.1):", round(BF_10, 3)))
# *Discussion Point*: BF ~ 7 falls in the 3-20 range, considered "substantial" evidence for H1: theta < 0.1.
# --- Predictive Distributions ---
# Using rmutil package for Beta-Binomial calculations
# library(rmutil) # Make sure package is loaded
support <- 0:N
# Prior Predictive (using elicited prior parameters)
prior_m <- my_prior_a / (my_prior_a + my_prior_b)
prior_s <- my_prior_a + my_prior_b
prior_pred_probs <- rmutil::dbetabinom(support, size = N, m = prior_m, s = prior_s)
print("Prior Predictive Probabilities (first few):")
print(head(prior_pred_probs))
print(paste("Sum check (prior predictive):", sum(prior_pred_probs)))
# Posterior Predictive (using posterior parameters)
# *Correction*: Use posterior mean (m) and concentration (s) for rmutil
posterior_m <- my_posterior_a / (my_posterior_a + my_posterior_b)
posterior_s <- my_posterior_a + my_posterior_b
posterior_pred_probs <- rmutil::dbetabinom(support, size = N, m = posterior_m, s = posterior_s)
print("Posterior Predictive Probabilities (first few):")
print(head(posterior_pred_probs))
print(paste("Sum check (posterior predictive):", sum(posterior_pred_probs)))
# Plot Posterior Predictive
plot(support, posterior_pred_probs, type="h", ylab="Posterior Predictive Probability",
main="Posterior Predictive Distribution (Elicited Prior)", xlab="k (Successes in N=20)")
points(support, posterior_pred_probs, col="red", pch=16)
abline(v = N * posterior_m, col="blue", lwd=2, lty=2) # Add theoretical mean E[Y_new|y]
# Simulate from Posterior Predictive (Correct Two-Step Method)
# *Discussion Point*: This demonstrates drawing theta* from posterior, then Y_new from likelihood.
num_sims <- 100000
# Step 1: Draw from posterior Beta(a_post, b_post)
theta_posterior_sim <- rbeta(num_sims, my_posterior_a, my_posterior_b)
# Step 2: Draw from Binomial(N, theta*)
Y_posterior_sim <- rbinom(num_sims, size=N, prob=theta_posterior_sim)
# Compare simulated mean to theoretical posterior predictive mean
print(paste("Theoretical Post Pred Mean:", round(N * posterior_m, 4)))
print(paste("Simulated Post Pred Mean:", round(mean(Y_posterior_sim), 4)))
```
## Explanation and Discussion
This R script performs a Bayesian analysis for a Binomial likelihood $Y \sim Binomial(N, \theta)$, where $\theta$ is the unknown probability of success. It specifically uses the conjugate Beta prior, $\theta \sim Beta(a,b)$.
**1. Prior Elicitation:**
* The primary goal of the first part is **prior elicitation**: finding the hyperparameters $a$ and $b$ of the Beta prior that match specific, pre-stated beliefs about $\theta$.
* **Beliefs Used:**
* The prior expected value $E[\theta]$ should be 0.1.
* The prior probability $P(0.05 \le \theta \le 0.20)$ should be approximately 0.7.
* **Method:**
* It leverages the **reparameterization** of the Beta distribution in terms of its mean $\mu = a/(a+b)$ and concentration $\psi = a+b$. This is often more intuitive for elicitation. *(Discussion Point: $(\mu, \psi)$ are also valid hyperparameters defining the prior).*
* The first belief directly fixes the target mean $\mu_0 = 0.1$.
* The second belief requires finding the concentration $\psi$ such that the resulting $Beta(\mu_0 \psi, (1-\mu_0)\psi)$ distribution assigns approximately 0.7 probability to the interval $[0.05, 0.20]$.
* This is achieved numerically using R's `uniroot` function to find the value of $\psi$ where the function `prior_prob(psi) - 0.7` equals zero.
* **Justification:** *(Discussion Point: The prior mean (0.1) and interval probability (0.7) represent beliefs held *before* seeing the current data, perhaps from expert opinion or previous studies. Prior elicitation translates these into a usable mathematical format.)*
**2. Posterior Analysis:**
* **Bayesian Update:** Once the prior parameters $(a, b)$ are determined (elicited), the script uses the observed data ($N=20, y_{obs}=0$) to calculate the posterior parameters ($a_{post}, b_{post}$) using the simple conjugate update rules: $a_{post} = a + y_{obs}$ and $b_{post} = b + N - y_{obs}$.
* **Visualization:** It plots the elicited prior, the (scaled) likelihood function, and the resulting posterior distribution. This visually demonstrates how the data pulls the belief from the prior towards values consistent with the likelihood (in this case, towards $\theta=0$ since $y_{obs}=0$).
* **Summaries:** It calculates standard posterior summaries:
* **Point Estimates:** Posterior mean, median, and mode (MAP).
* **Interval Estimates:** 95% Equal-Tailed (ET) and Highest Posterior Density (HPD) credible intervals, providing a range for plausible values of $\theta$.
* **Hypothesis Testing:**
* It calculates the posterior probability for a composite hypothesis (e.g., $P(\theta \le 0.1 | y_{obs})$).
* It calculates the **Bayes Factor (BF)** to compare competing hypotheses (e.g., $H_1: \theta < 0.1$ vs $H_0: \theta \ge 0.1$). *(Discussion Point: The script calculates the BF for different hypothesis pairings. The value BF $\approx 7$ corresponds to the evidence for $H_1: \theta < 0.1$ vs $H_0: \theta \ge 0.1$ and is considered "substantial" evidence according to common scales.)*
* It demonstrates testing a point-null hypothesis (e.g., $H_0: \theta = 0.1$) by checking if the value falls within the credible interval.
* **Predictive Distributions:**
* It calculates the theoretical **prior predictive distribution** (Beta-Binomial with prior parameters $a, b$) and the **posterior predictive distribution** (Beta-Binomial with posterior parameters $a_{post}, b_{post}$) using the corrected `rmutil::dbetabinom` function call (`m=`mean, `s=`concentration).
* It demonstrates how to **simulate** from these predictive distributions using the correct two-step Bayesian approach. *(Discussion Point: For the posterior predictive simulation, this involves first drawing $\theta^* \sim Beta(a_{post}, b_{post})$ and then drawing $Y_{new} \sim Binomial(N, \theta^*)$, repeated many times. This correctly incorporates parameter uncertainty, unlike using a single point estimate for $\theta$.)*
**Overall Purpose:** This exercise provides a comprehensive walkthrough of a conjugate Bayesian analysis, emphasizing the important step of prior elicitation based on specific beliefs and demonstrating how to extract various forms of inference (estimation, testing, prediction) from the resulting posterior distribution.
```