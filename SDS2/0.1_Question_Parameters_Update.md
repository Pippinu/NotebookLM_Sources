QUESTION:
Why you update parameters in this way? (Beta Binomial Model)
# Update the posterior parameters based on the observed outcome
if (outcome == 1) { # Heads
posterior_alpha <- current_prior_alpha + 1
posterior_beta <- current_prior_beta
} else { # Tails
posterior_alpha <- current_prior_alpha
posterior_beta <- current_prior_beta + 1
}
ANSWER:
The way we update the parameters $\alpha$ and $\beta$ of the Beta distribution in the online Bayesian inference example stems from the concept of a **conjugate prior**. The **Beta distribution** is the conjugate prior for the **Bernoulli** (single coin flip) and **Binomial** (multiple coin flips) likelihoods.
### 1. The Likelihood Function for a Bernoulli Trial
For a single coin flip, the outcome $y$ can be heads ($y=1$) with probability $\theta$, or tails ($y=0$) with probability $1-\theta$. The likelihood function is:
$$P(y | \theta) = \theta^y (1-\theta)^{(1-y)}$$
Specifically:
- If $y=1$ (heads): $P(y=1 | \theta) = \theta$
- If $y=0$ (tails): $P(y=0 | \theta) = 1-\theta$
### 2. The Beta Prior Distribution
The Beta distribution with shape parameters $\alpha > 0$ and $\beta > 0$ has a probability density function (PDF) proportional to:
$$P(\theta | \alpha, \beta) \propto \theta^{\alpha - 1} (1-\theta)^{\beta - 1}, \quad \theta \in [0, 1]$$
### 3. Applying Bayes' Theorem
The posterior distribution is proportional to the product of the likelihood and the prior:
$$P(\theta | y, \alpha, \beta) \propto P(y | \theta) \cdot P(\theta | \alpha, \beta)$$
### 4. Updating for Heads ($y = 1$)
If we observe a head, the posterior becomes:
$$
\begin{aligned}
P(\theta | y=1, \alpha, \beta) &\propto \theta^1 (1-\theta)^0 \cdot \theta^{\alpha - 1} (1-\theta)^{\beta - 1} \\
&\propto \theta^{(\alpha - 1) + 1} (1-\theta)^{(\beta - 1) + 0} \\
&\propto \theta^{\alpha} (1-\theta)^{\beta - 1}
\end{aligned}
$$
This is proportional to the PDF of a Beta distribution with parameters $\alpha + 1$ and $\beta$. Thus, the updated parameters are:
- New $\alpha = \text{current } \alpha + 1$
- New $\beta = \text{current } \beta$
### 5. Updating for Tails ($y = 0$)
If we observe a tail, the posterior becomes:
$$
\begin{aligned}
P(\theta | y=0, \alpha, \beta) &\propto \theta^0 (1-\theta)^1 \cdot \theta^{\alpha - 1} (1-\theta)^{\beta - 1} \\
&\propto \theta^{(\alpha - 1) + 0} (1-\theta)^{(\beta - 1) + 1} \\
&\propto \theta^{\alpha - 1} (1-\theta)^{\beta}
\end{aligned}
$$
This is proportional to the PDF of a Beta distribution with parameters $\alpha$ and $\beta + 1$. Thus, the updated parameters are:
- New $\alpha = \text{current } \alpha$
- New $\beta = \text{current } \beta + 1$