Here's a breakdown of the main conjugate model examples covered in detail and their corresponding slides:
1. **Binomial Model & Beta Prior:**
* **Slides:** Pages 24-29 (Sources 45-57)
* **Content:** This section details the most classic example. It covers:
* Setting up the Binomial likelihood (page 24).
* Introducing the conjugate Beta prior distribution and its key properties (mean, variance, mode, Beta function) (page 25-26).
* Discussing reparameterization of the Beta distribution (mean and concentration/strength) (page 26-27).
* Deriving the Beta posterior distribution and the simple updating rules for the hyperparameters (page 28).
* Interpreting the posterior mean as a weighted average of the prior mean and the data mean, and discussing the update in the reparameterized form (page 29).
* **(Related Application):** Slide 30 (Source 58) then suggests applying this analysis to a specific example (rare disease prevalence), likely using the concepts from pages 24-29.
2. **Poisson Model & Gamma Prior:**
* **Slides:** Pages 71-74 (Sources 140-144)
* **Content:** This section covers:
* Setting up the Poisson likelihood for i.i.d. counts (page 71).
* Identifying the Gamma distribution family as conjugate by matching the functional form (page 71-72).
* Deriving the Gamma posterior and the updating rules for the Gamma parameters (rate and shape) (page 72).
* Showing a similar reparameterization and weighted average interpretation for the posterior mean, analogous to the Binomial-Beta case (pages 73-74).
* **(Related Concepts):** Slides 75-82 (Sources 145-157) discuss the prior and posterior predictive distributions (Negative Binomial) that arise from this conjugate setup.
3. **Normal Model (Known Variance) & Normal Prior:**
* **Slides:** Pages 115-119 (Sources 262-270)
* **Content:** This focuses on the case where you model data with a Normal distribution but assume you already know its variance:
* Setting up the Normal likelihood (known variance $\sigma^2$) and the Normal prior for the unknown mean $\theta$ (parameterized by $\mu_0, \tau^2_0$) (page 115).
* Deriving the Normal posterior for $\theta$ and the updating formulas for the posterior mean $\mu_y$ and posterior variance $\tau^2_y$ (page 115).
* Discussing the alternative parameterization using *precision* (inverse of variance) and showing the clean updating rules in that form ($\nu_y = \nu_0 + n\psi$) (page 116-117).
* Interpreting the posterior mean as a weighted average, where the weight depends on the relative precisions (strengths) of the prior and the data (pages 117-119).
4. **Normal Model (Unknown Mean & Variance) & Normal-Inverse Gamma Prior:**
* **Slides:** Pages 120-128 (Sources 271-286)
* **Content:** This addresses the more realistic scenario where both Normal parameters are unknown:
* Setting up the Normal likelihood with unknown mean $\theta$ and precision $\lambda = 1/\sigma^2$ (page 120).
* Introducing the conjugate *joint* prior, specified hierarchically: $\pi(\theta, \lambda) = \pi(\theta|\lambda)\pi(\lambda)$, where $\theta|\lambda$ is Normal and $\lambda$ is Gamma (or equivalently, $\sigma^2$ is Inverse Gamma) (page 120, 125). This prior involves 4 hyperparameters (page 122).
* Discussing parameterization conventions (Inverse Gamma vs Gamma, rate vs scale) (page 121, 205-207).
* Deriving the marginal prior distribution for $\theta$ (integrating out $\sigma^2$ or $\lambda$), which turns out to be a Student's t-distribution (pages 123, 126).
* Stating the form of the joint posterior (which remains Normal-Inverse Gamma) and providing the complex updating formulas for the 4 posterior hyperparameters (page 127).
* Stating the marginal posterior distribution for $\theta$, which is also a Student's t-distribution (page 128).
* **(Mathematical Details):** Slides 129-134 (Sources 287-293) provide the algebraic steps for deriving the posterior update formulas mentioned on page 127.
**(Related Theoretical Point):**
* **Exponential Family & Conjugacy:**
* **Slides:** Pages 85-88 (Sources 160-165)
* **Content:** This section presents a more general theoretical result, showing that for any likelihood belonging to the widely applicable exponential family, a general form for the conjugate prior exists, unifying some of the previous examples.
This breakdown shows how the slides introduce the general concept and then cycle through detailed applications for the Binomial, Poisson, and Normal models, likely aligning with when those models are taught in the broader course structure.