## 1. Introduction
## 2. Physical Layer
## 3. Link Layer
### Question: Error-Correcting Codes and Hamming Distance

You are designing a communication system that uses a block code. After careful design, you determine that the *minimum Hamming distance* of your code is 7.

Based on this minimum Hamming distance:

1.  **What is the maximum number of single-bit errors that this code can reliably *detect*?** Explain your reasoning based on the rule we discussed.
2.  **What is the maximum number of single-bit errors that this code can reliably *correct*?** Explain your reasoning based on the rule we discussed.
3.  **If a valid codeword of `00000000000` is transmitted, but the receiver receives `00000100110`, how many errors occurred? Would this code be able to correct this received word back to the original `00000000000`? Justify your answer.**

### Answer and Explanation

Given that the **minimum Hamming distance ($d_{min}$) of the code is 7**:

1.  **Maximum number of single-bit errors this code can reliably *detect***:
    * **Answer:** At most **6** errors can be reliably detected.
    * **Reasoning:** The rule for error detection states that a code with a minimum Hamming distance of $d_{min}$ can reliably detect up to $d_{min} - 1$ errors. In this case, $7 - 1 = 6$. This means if up to 6 single-bit errors occur, the corrupted codeword will never be transformed into another valid codeword; it will always result in an invalid sequence, which the receiver can recognize as an error.

2.  **Maximum number of single-bit errors this code can reliably *correct***:
    * **Answer:** At most **3** errors can be reliably corrected.
    * **Reasoning:** The rule for error correction states that a code with a minimum Hamming distance of $d_{min}$ can reliably correct up to $d_{errors}$ errors, where $d_{errors} = \lfloor \frac{d_{min} - 1}{2} \rfloor$. In this case, $\lfloor \frac{7 - 1}{2} \rfloor = \lfloor \frac{6}{2} \rfloor = 3$. This means that the valid codewords are "far enough apart" in the signal space. Specifically, a minimum distance of $2d_{errors} + 1$ (here, $2 \times 3 + 1 = 7$) ensures that even if up to 3 errors occur, the resulting corrupted codeword will *always* be closer (in Hamming distance) to its *original* valid codeword than to *any other* valid codeword. This allows the receiver to unambiguously identify and correct the original message.

3.  **Analysis of received word `00000100110` from `00000000000`**:
    * **Number of Errors:** By comparing `00000000000` with `00000100110`, we find differences in the 6th, 9th, and 10th bit positions. Therefore, **3 single-bit errors occurred**.
    * **Ability to Correct:** Yes, this code **would be able to correct** the received word `00000100110` back to the original `00000000000`.
    * **Justification:** As determined in part 2, this code can reliably correct up to 3 single-bit errors. Since only 3 errors occurred in this specific transmission, the corrupted word `00000100110` falls within the correctable range. The receiver would calculate the Hamming distance to all valid codewords and find that `00000000000` is the unique closest valid codeword, allowing for successful correction.

---

### Quiz: Pure ALOHA vs. Slotted ALOHA

You have two separate communication networks, each using a different ALOHA protocol to share a single channel:

1.  **Network A uses Pure ALOHA.**
2.  **Network B uses Slotted ALOHA.**

Both networks have many users who generate frames randomly and independently, and they have the same average frame generation rate (G).

Consider a situation where a new frame is generated by a user in Network A and another new frame is generated by a user in Network B at roughly the same arbitrary moment in time (e.g., both users finish typing and hit 'send' simultaneously).

1.  **For the frame in Network A (Pure ALOHA), describe its "vulnerable period" for collision. What does this mean in practical terms for when other frames could cause a collision?**
2.  **For the frame in Network B (Slotted ALOHA), describe its "vulnerable period" for collision. How does the protocol's rule impact when other frames could cause a collision, compared to Network A?**
3.  **Based on your answers to 1 and 2, explain *why* Slotted ALOHA achieves a higher maximum throughput than Pure ALOHA.**

### Answer and Explanation

1.  **For the frame in Network A (Pure ALOHA), describe its "vulnerable period" for collision. What does this mean in practical terms for when other frames could cause a collision?**
    * **Description:** In Pure ALOHA, if a frame begins transmission at time `t`, its "vulnerable period" for collision extends for a duration of **two frame times**. This period spans from `t - T_frame` to `t + T_frame`, where `T_frame` is the time it takes to transmit one full frame.
    * **Practical Terms:** This means a frame is vulnerable to collision from two types of other frames:
        * Those that started their transmission **during the `T_frame` interval *before* our frame began**, as they would overlap with the beginning of our frame.
        * Those that start their transmission **during our frame's *own* transmission time**, as they would overlap with the end of our frame.
    * Because there is no channel sensing, users transmit "blindly," making this wide window of vulnerability lead to frequent collisions.

2.  **For the frame in Network B (Slotted ALOHA), describe its "vulnerable period" for collision. How does the protocol's rule impact when other frames could cause a collision, compared to Network A?**
    * **Description:** In Slotted ALOHA, transmissions are strictly synchronized to begin only at the start of discrete, fixed-duration time slots (each slot being one `T_frame` long). Due to this rule, a frame's "vulnerable period" for collision is drastically reduced to **only the single slot in which it is transmitted** (i.e., one `T_frame` duration).
    * **Impact Compared to Network A:** This synchronization significantly limits collision opportunities. A frame can no longer be corrupted by another frame that started "just before" it, because any such frame would have had to start in a *previous* slot and would have completed (or entirely occupied) that slot. Collisions can *only* occur if two or more frames attempt to start their transmission **simultaneously at the beginning of the *same* slot**.

3.  **Based on your answers to 1 and 2, explain *why* Slotted ALOHA achieves a higher maximum throughput than Pure ALOHA.**
    * **Explanation:** Slotted ALOHA achieves a higher maximum throughput than Pure ALOHA primarily because its synchronization rule **halves the "vulnerable period" for collisions**. By restricting transmissions to slot boundaries, it eliminates partial overlaps caused by frames starting at arbitrary times. This reduction in the time window during which a collision can occur directly translates to a *lower probability of collision* for any given channel load. A lower collision rate means more successful frame transmissions, allowing Slotted ALOHA to process more data (achieve higher throughput) before the channel becomes saturated with unproductive collisions.

---

### Question: CSMA Variations

Imagine a communication channel with multiple devices that want to transmit data. At a certain moment, the channel is currently busy with a long transmission.

Describe the specific behavior of a device that has a frame ready to send in each of the following CSMA scenarios, once the channel becomes idle. Also, explain a key advantage or disadvantage of that specific behavior compared to the others.

1.  **If the device is using 1-persistent CSMA.**
2.  **If the device is using nonpersistent CSMA.**
3.  **If the device is using CSMA/CD, and after it starts transmitting, it detects a collision.**

### Answer and Explanation

1.  **If the device is using 1-persistent CSMA.**
    * **Behavior:** The station continuously senses the channel. As soon as it detects that the channel becomes idle, it immediately begins transmitting its frame.
    * **Key Disadvantage:** If multiple stations are waiting for the channel to become idle, they will all detect the idle state simultaneously and transmit immediately, leading to a guaranteed collision among them. This aggressive behavior can result in high collision rates, especially under moderate to heavy network loads.

2.  **If the device is using nonpersistent CSMA.**
    * **Behavior:** If the station finds the channel busy, it does not continuously sense it. Instead, it waits for a random period of time before sensing the channel again. If the channel is then idle, it transmits; otherwise, it waits another random period.
    * **Key Advantage:** This approach significantly reduces the probability of collisions. By forcing stations to wait random durations, it prevents multiple stations from attempting to transmit simultaneously as soon as the channel becomes free.

3.  **If the device is using CSMA/CD, and after it starts transmitting, it detects a collision.**
    * **Behavior:** The station transmits its frame while simultaneously sensing the channel. If it detects a mismatch between its transmitted signal and the signal on the channel (indicating a collision), it immediately stops transmitting (aborts the frame), sends a brief "jam signal" to ensure other stations detect the collision, and then waits a random amount of time before attempting retransmission.
    * **Key Advantage:** This mechanism saves significant channel bandwidth and transmission time. Unlike protocols without collision detection, it prevents the transmission of an entire frame that is already corrupted, thus reducing wasted resources and improving overall channel efficiency.

---

### Question: Company Network Troubleshooting

A new intern is setting up a new device on a company network and causes some issues.

1.  **Framing Mistake**: The device is supposed to send data using a **Flag Bits with Bit Stuffing** protocol (e.g., HDLC). However, the intern misconfigures the device, and it sends a data payload containing the sequence `01111111111110` (which has six consecutive '1's as part of the data) *without* applying bit stuffing.
    * **What immediate problem will this specific data sequence cause at the receiver's data link layer, and why? How does the lack of stuffing affect frame synchronization?**

2.  **Error Handling Choices**: The company's core network link is very stable and has a low average bit error rate, but occasional, short bursts of noise can occur. The intern suggests implementing a **single parity bit** for all data frames for simple error detection.
    * **Would a single parity bit be sufficient to reliably detect *all* errors caused by the *occasional, short bursts of noise*? Explain its fundamental limitation regarding error detection in such scenarios.**
    * **If the company wanted to ensure that *all* single-bit errors were not only detected but also *corrected* without retransmission on this stable link, what specific property would the chosen error-correcting code need to have in terms of its minimum Hamming distance?**

3.  **Network Access and Forwarding**: The new device is connected to a **Switched Ethernet** network. Initially, the switch's MAC address table has no entries for this newly connected device. The device then sends its first data frame, which happens to be a **broadcast ARP request**, to find the MAC address of a server.
    * **Describe the *first action* the switch will perform upon receiving this initial frame from the new device, directly relating it to the switch's self-learning capability.**
    * **Describe the *second action* the switch will perform based on the frame's destination (a broadcast ARP request), explaining how it handles this type of frame when it might not yet know the destination's MAC address.**

### Answer and Explanation

1.  **Framing Mistake: Misconfigured Flag Bits with Bit Stuffing**
    * **Problem:** The flag pattern for Flag Bits with Bit Stuffing is `01111110`. If the device sends a data payload with six consecutive '1's (`111111`) without stuffing a '0', this sequence (when combined with adjacent '0's from other parts of the frame) will likely form the exact flag pattern. The receiver will mistakenly interpret this `01111110` pattern *within the data payload* as a legitimate **end-of-frame FLAG**. This causes **premature frame termination**.
    * **Impact on Synchronization:** This leads to a severe **loss of frame synchronization**. The receiver will then wrongly assume the next bits are the start of a new frame and will scan for another start-of-frame FLAG, discarding all the remaining data from the original, prematurely terminated frame and potentially misinterpreting subsequent legitimate frames until it can successfully re-synchronize (which involves actively scanning for a valid start flag and validating a new frame via checksum).

2.  **Error Handling Choices: Single Parity Bit and Error Correction**
    * **Single Parity Bit Sufficiency:** A single parity bit is **not sufficient** to reliably detect *all* errors caused by occasional, short bursts of noise.
    * **Fundamental Limitation:** Its fundamental limitation is that it can **only detect an *odd* number of bit flips** within the protected block. If a burst of noise causes an an *even* number of bits to flip (e.g., 2, 4, 6 bits), the parity bit will remain correct, and the error will pass **undetected**.
    * **Error Correction Property:** To ensure that *all* **single-bit errors** are reliably detected *and* **corrected** without retransmission, the chosen error-correcting code must have a **minimum Hamming distance ($d_{min}$) of at least 3**. This is because for correcting $d=1$ error, the rule is $d_{min} \ge 2d + 1$, which means $d_{min} \ge 2(1) + 1 = 3$.

3.  **Network Access and Forwarding: Switched Ethernet with Broadcast ARP Request**
    * **First Action (Self-Learning):** Upon receiving this initial frame from the new device, the switch will perform **self-learning**. It will examine the **source MAC address** of the incoming frame (which is the new device's MAC address). Since this MAC address is not yet in its initially empty MAC address table, the switch will **add an entry** to its table: mapping the new device's source MAC address to the specific **interface (port)** on which the frame arrived, along with a timestamp.
    * **Second Action (Handling Broadcast):** The switch will then look at the **destination MAC address** of the incoming frame. For a **broadcast ARP request**, the destination MAC address is the special **broadcast MAC address** (`FF:FF:FF:FF:FF:FF`). When a switch receives a frame with a broadcast destination MAC address, it performs **flooding**: it sends a copy of the frame to **all its interfaces (ports) *except* the one on which it arrived**. This ensures the broadcast message reaches all devices on the local network segment.

---
# 4. Network Layer

### Question: Distance Vector Update Scenario

Imagine a network where **Router B** is trying to determine the best path to reach a specific **Destination Host X**. Router B has direct connections to several other routers, including **Router A** and **Router C**.

You know the following information for Router B:
* Its current best-known path to **Destination Host X** is via **Router A**, with a total estimated cost of **10**.
* Its direct cost to communicate with **Router A** is **2**.
* Its direct cost to communicate with **Router C** is **3**.

Now, **Router C** sends its periodic distance vector update to Router B. In this update, Router C advertises that its current best-known path to **Destination Host X** has an estimated cost of **5**.

1.  Based solely on the information Router C just sent and Router B's direct cost to C, what is the *potential total cost* for Router B to reach Destination Host X if it were to route through Router C? Show your calculation.
2.  Given Router B's current best path to Destination Host X (via Router A with a cost of 10) and the new potential path via Router C (calculated in part 1), would Router B update its routing table to use Router C as the next hop for Destination Host X? Explain your reasoning based on the core update rule of Distance Vector Routing.
3.  How does the general process of Distance Vector Routing, where each router selects its next hop based on the minimum sum of its direct cost to a neighbor and that neighbor's advertised cost to the destination, reflect the **Bellman optimality principle**?

### Answer and Explanation

1.  **Based solely on the information Router C just sent and Router B's direct cost to C, what is the *potential total cost* for Router B to reach Destination Host X if it were to route through Router C? Show your calculation.**
    * **Calculation and Explanation:**
        * Router C's advertised best cost to Destination Host X = 5.
        * Router B's direct cost to Router C = 3.
        * **Potential total cost for Router B via Router C = (Router B to Router C direct cost) + (Router C's advertised cost to X)**
        * Calculation: $3 + 5 = 8$.
        * Therefore, the potential total cost for Router B to reach Destination Host X if it were to route through Router C is **8**.

2.  **Given Router B's current best path to Destination Host X (via Router A with a cost of 10) and the new potential path via Router C (calculated in part 1), would Router B update its routing table to use Router C as the next hop for Destination Host X? Explain your reasoning based on the core update rule of Distance Vector Routing.**
    * **Explanation:** Yes, Router B would update its routing table. Router B's current best path to Destination Host X has a cost of 10 (via Router A). The newly calculated potential path via Router C has a cost of 8. According to the core update rule of Distance Vector Routing, a router always selects the path that offers the *minimum (shortest) total cost* to a given destination. Since $8 < 10$, Router B would update its routing table to set Router C as the next hop for Destination Host X, with the new cost of 8.

3.  **How does the general process of Distance Vector Routing, where each router selects its next hop based on the minimum sum of its direct cost to a neighbor and that neighbor's advertised cost to the destination, reflect the **Bellman optimality principle**?**
    * **Explanation:** The Bellman optimality principle states that if a path from a source to a destination is optimal, then any subpath within that optimal path is also optimal. Distance Vector Routing embodies this principle by continually making locally optimal decisions. When a router computes its best path to a destination by choosing the neighbor that offers the minimum combined cost (its direct cost to the neighbor plus the neighbor's advertised cost to the destination), it inherently assumes that the neighbor's advertised cost represents an optimal path *from that neighbor* to the destination. By aggregating these local optimal choices, the algorithm iteratively works towards establishing globally optimal paths across the entire network, consistent with the Bellman optimality principle.

---